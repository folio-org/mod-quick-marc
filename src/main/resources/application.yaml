spring:
  application:
    name: mod-quick-marc
  threads:
    virtual:
      enabled: true
  datasource:
    hikari:
      connectionTimeout: ${DB_CONNECTION_TIMEOUT:30000}
      idleTimeout: ${DB_IDLE_TIMEOUT:600000}
      keepaliveTime: ${DB_KEEPALIVE_TIME:0}
      maxLifetime: ${DB_MAX_LIFETIME:1800000}
      validationTimeout: ${DB_VALIDATION_TIMEOUT:5000}
      maximumPoolSize: ${DB_MAXPOOLSIZE:10}
      minimumIdle: ${DB_MINIMUM_IDLE:10}
      initializationFailTimeout: ${DB_INITIALIZATION_FAIL_TIMEOUT:30000}
      leakDetectionThreshold: ${DB_LEAK_DETECTION_THRESHOLD:60000}
    url: jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_DATABASE:modules}
    username: ${DB_USERNAME:folio_admin}
    password: ${DB_PASSWORD:folio_admin}
  kafka:
    bootstrap-servers: ${KAFKA_HOST:localhost}:${KAFKA_PORT:9092}
    consumer:
      enable-auto-commit: true
      auto-commit-interval: 1000
  jpa:
    open-in-view: false
    hibernate:
      ddl-auto: none
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true
    show-sql: false
  liquibase:
    changeLog: classpath:db/changelog/changelog-master.xml
    enabled: true
  jackson:
    default-property-inclusion: NON_EMPTY
  cache:
    cache-names:
      - job-profiles
      - qm-update-results
      - data-import-results
      - linking-rules-results
      - specifications
      - mapping-metadata-cache
    caffeine:
      spec: maximumSize=500,expireAfterAccess=3600s
  cloud:
    openfeign:
      okhttp:
        enabled: true
  sql:
    init:
      # to boot up application despite of any DB connection issues
      continue-on-error: true
folio:
  environment: ${ENV:folio}
  cache:
    spec:
      specifications:
        maximum-size: 500
        ttl: 24h
  qm:
    creation-status:
      clear:
        initial-delay-ms: 3_600_000
        fixed-delay-ms: 86_400_000
  tenant:
    validation:
      enabled: true
  logging:
    request:
      enabled: false
    feign:
      enabled: true
      level: basic
  kafka:
    numberOfPartitions: ${NUMBER_OF_PARTITIONS:5}
    replicationFactor: ${REPLICATION_FACTOR:1}
    topics:
      - name: di-completed
        numPartitions: ${NUMBER_OF_PARTITIONS:1}
        replicationFactor: ${REPLICATION_FACTOR:1}
      - name: di-error
        numPartitions: ${NUMBER_OF_PARTITIONS:1}
        replicationFactor: ${REPLICATION_FACTOR:1}
      - name: qm-completed
        numPartitions: ${NUMBER_OF_PARTITIONS:1}
        replicationFactor: ${REPLICATION_FACTOR:1}
    listener:
      di-completed:
        concurrency: ${KAFKA_EVENTS_CONCURRENCY:2}
        topic-pattern: ${KAFKA_EVENTS_CONSUMER_PATTERN:(${folio.environment}\.)[a-zA-z0-9-]+\.\w+\.DI_COMPLETED}
        group-id: ${folio.environment}-mod-quick-marc-di-completed-group
      di-error:
        concurrency: ${KAFKA_EVENTS_CONCURRENCY:2}
        topic-pattern: ${KAFKA_EVENTS_CONSUMER_PATTERN:(${folio.environment}\.)[a-zA-z0-9-]+\.\w+\.DI_ERROR}
        group-id: ${folio.environment}-mod-quick-marc-di-error-group
      qm-completed:
        concurrency: ${KAFKA_EVENTS_CONCURRENCY:2}
        topic-pattern: ${KAFKA_EVENTS_CONSUMER_PATTERN:(${folio.environment}\.)[a-zA-z0-9-]+\.\w+\.QM_COMPLETED}
        group-id: ${folio.environment}-mod-quick-marc-qm-group
      specification-updated:
        concurrency: ${KAFKA_EVENTS_CONCURRENCY:1}
        topic-pattern: ${KAFKA_EVENTS_CONSUMER_PATTERN:(${folio.environment}\.)(.*\.)specification-storage\.specification\.updated}
        group-id: ${folio.environment}-mod-quick-marc-specification-group
        shared-group: false
management:
  endpoints:
    web:
      exposure:
        include: info,health,liquibase,threaddump,heapdump,loggers
      base-path: /admin
  endpoint:
    loggers:
      access: unrestricted
server:
  port: 8081
